{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stochastic_predictors.modules.experiment.metrics import *\n",
    "from stochastic_predictors.modules.experiment.attacks import *\n",
    "from stochastic_predictors.modules.model.cnn import StochasticCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "train_dataset = FashionMNIST(\"../data\", download=True, train=True, transform=transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataset = FashionMNIST(\"../data\", download=False, train=False, transform=transforms)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 2124.48it/s]\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Using device:\", dev)\n",
    "\n",
    "# load experiment configuration file\n",
    "with open(\"../experiments/exp-b04/config-b04.yaml\") as config:\n",
    "    params = dict(yaml.load(config, Loader=yaml.FullLoader))\n",
    "\n",
    "# load model\n",
    "net = StochasticCNN(params[\"model\"], params[\"n_for_features\"], params[\"batch_norm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StochasticCNN(\n",
       "  (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (4): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): Conv2d(12, 12, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (7): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (9): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): ReLU()\n",
       "  (14): Conv2d(48, 48, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (15): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (17): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Conv2d(96, 96, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (20): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (21): Conv2d(96, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (22): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (23): ReLU()\n",
       "  (24): Conv2d(50, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (25): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU()\n",
       "  (27): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.train()\n",
    "net.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    key: list() for key in [\"train_obj\", \"val_obj\", \"train_acc\", \"val_acc\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchattacks import FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "atk = FGSM(net, eps=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 100\n",
      "\ttrain loss: 1.9968994027455649, val loss: 2.0044271522521973\n",
      "\ttrain accuracy 0.63655, val accuracy: 0.4748\n",
      "Epoch: 2 / 100\n",
      "\ttrain loss: 1.8692556037902832, val loss: 1.9975205463409424\n",
      "\ttrain accuracy 0.7668, val accuracy: 0.4804\n",
      "Epoch: 3 / 100\n",
      "\ttrain loss: 1.816210550181071, val loss: 1.9509641735076904\n",
      "\ttrain accuracy 0.7986833333333333, val accuracy: 0.516\n",
      "Epoch: 4 / 100\n",
      "\ttrain loss: 1.7781397764205933, val loss: 1.940529877090454\n",
      "\ttrain accuracy 0.8174833333333333, val accuracy: 0.5241\n",
      "Epoch: 5 / 100\n",
      "\ttrain loss: 1.745952007039388, val loss: 1.974429902076721\n",
      "\ttrain accuracy 0.83185, val accuracy: 0.4872\n",
      "Epoch: 6 / 100\n",
      "\ttrain loss: 1.722718989054362, val loss: 1.953197012901306\n",
      "\ttrain accuracy 0.84015, val accuracy: 0.5081\n",
      "Epoch: 7 / 100\n",
      "\ttrain loss: 1.7005228888829549, val loss: 1.9340782049179077\n",
      "\ttrain accuracy 0.8502666666666666, val accuracy: 0.5265\n",
      "Epoch: 8 / 100\n",
      "\ttrain loss: 1.6847127026240032, val loss: 1.9335372650146485\n",
      "\ttrain accuracy 0.8564833333333334, val accuracy: 0.5265\n",
      "Epoch: 9 / 100\n",
      "\ttrain loss: 1.6686875450134278, val loss: 1.936129793548584\n",
      "\ttrain accuracy 0.8619666666666667, val accuracy: 0.5211\n",
      "Epoch: 10 / 100\n",
      "\ttrain loss: 1.6551048938115438, val loss: 1.949502569770813\n",
      "\ttrain accuracy 0.8685, val accuracy: 0.5096\n",
      "Epoch: 11 / 100\n",
      "\ttrain loss: 1.6441721101760864, val loss: 1.9169138130187988\n",
      "\ttrain accuracy 0.8718666666666667, val accuracy: 0.543\n",
      "Epoch: 12 / 100\n",
      "\ttrain loss: 1.6334506079991657, val loss: 1.9724699962615966\n",
      "\ttrain accuracy 0.8782666666666666, val accuracy: 0.4857\n",
      "Epoch: 13 / 100\n",
      "\ttrain loss: 1.6257459851582845, val loss: 1.959244829559326\n",
      "\ttrain accuracy 0.8800166666666667, val accuracy: 0.5\n",
      "Epoch: 14 / 100\n",
      "\ttrain loss: 1.6172651805241902, val loss: 1.9196968618392944\n",
      "\ttrain accuracy 0.8854666666666666, val accuracy: 0.5396\n",
      "Epoch: 15 / 100\n",
      "\ttrain loss: 1.6094210103352864, val loss: 1.9556749591827391\n",
      "\ttrain accuracy 0.8896166666666666, val accuracy: 0.5031\n",
      "Epoch: 16 / 100\n",
      "\ttrain loss: 1.6037140331268311, val loss: 1.9470247917175294\n",
      "\ttrain accuracy 0.89165, val accuracy: 0.5114\n",
      "Epoch: 17 / 100\n",
      "\ttrain loss: 1.5975057832082113, val loss: 1.9473265661239625\n",
      "\ttrain accuracy 0.8959833333333334, val accuracy: 0.5121\n",
      "Epoch: 18 / 100\n",
      "\ttrain loss: 1.5915792092641194, val loss: 1.9299468687057495\n",
      "\ttrain accuracy 0.8991, val accuracy: 0.5289\n",
      "Epoch: 19 / 100\n",
      "\ttrain loss: 1.5863698980967205, val loss: 1.9327861101150512\n",
      "\ttrain accuracy 0.9018333333333334, val accuracy: 0.527\n",
      "Epoch: 20 / 100\n",
      "\ttrain loss: 1.5825847717285155, val loss: 1.926153588104248\n",
      "\ttrain accuracy 0.9042166666666667, val accuracy: 0.5332\n",
      "Epoch: 21 / 100\n",
      "\ttrain loss: 1.5783456468582153, val loss: 1.9314803220748902\n",
      "\ttrain accuracy 0.9065666666666666, val accuracy: 0.5278\n",
      "Epoch: 22 / 100\n",
      "\ttrain loss: 1.5741854145685832, val loss: 1.9415133834838867\n",
      "\ttrain accuracy 0.9094666666666666, val accuracy: 0.5176\n",
      "Epoch: 23 / 100\n",
      "\ttrain loss: 1.5706346370697022, val loss: 1.934573599243164\n",
      "\ttrain accuracy 0.9119, val accuracy: 0.5254\n",
      "Epoch: 24 / 100\n",
      "\ttrain loss: 1.5681362542470296, val loss: 1.924301291847229\n",
      "\ttrain accuracy 0.9132666666666667, val accuracy: 0.535\n",
      "Epoch: 25 / 100\n",
      "\ttrain loss: 1.5647474894205728, val loss: 1.9287928497314453\n",
      "\ttrain accuracy 0.9152333333333333, val accuracy: 0.5303\n",
      "Epoch: 26 / 100\n",
      "\ttrain loss: 1.5617182837804158, val loss: 1.952298137664795\n",
      "\ttrain accuracy 0.9175166666666666, val accuracy: 0.5075\n",
      "saving model checkpoint...\n",
      "Epoch: 27 / 100\n",
      "\ttrain loss: 1.5584730847676596, val loss: 1.9116408958435058\n",
      "\ttrain accuracy 0.9202, val accuracy: 0.5479\n",
      "Epoch: 28 / 100\n",
      "\ttrain loss: 1.5563247700373333, val loss: 1.9102124271392822\n",
      "\ttrain accuracy 0.9216166666666666, val accuracy: 0.5505\n",
      "Epoch: 29 / 100\n",
      "\ttrain loss: 1.5522480730692545, val loss: 1.95504330368042\n",
      "\ttrain accuracy 0.9242166666666667, val accuracy: 0.5041\n",
      "Epoch: 30 / 100\n",
      "\ttrain loss: 1.5516853298187256, val loss: 1.9403862728118897\n",
      "\ttrain accuracy 0.9239833333333334, val accuracy: 0.5196\n",
      "Epoch: 31 / 100\n",
      "\ttrain loss: 1.5486852012634278, val loss: 1.9304193891525268\n",
      "\ttrain accuracy 0.9268, val accuracy: 0.5291\n",
      "Epoch: 32 / 100\n",
      "\ttrain loss: 1.5473691184361775, val loss: 1.9276699535369872\n",
      "\ttrain accuracy 0.92765, val accuracy: 0.5317\n",
      "Epoch: 33 / 100\n",
      "\ttrain loss: 1.5446909016927084, val loss: 1.9557780532836915\n",
      "\ttrain accuracy 0.92935, val accuracy: 0.5044\n",
      "Epoch: 34 / 100\n",
      "\ttrain loss: 1.5431916356404622, val loss: 1.9324545166015625\n",
      "\ttrain accuracy 0.9306666666666666, val accuracy: 0.5258\n",
      "Epoch: 35 / 100\n",
      "\ttrain loss: 1.5420882062276204, val loss: 1.9182203582763673\n",
      "\ttrain accuracy 0.9312833333333334, val accuracy: 0.5424\n",
      "Epoch: 36 / 100\n",
      "\ttrain loss: 1.5399518187204997, val loss: 1.881406589126587\n",
      "\ttrain accuracy 0.9328333333333333, val accuracy: 0.579\n",
      "Epoch: 37 / 100\n",
      "\ttrain loss: 1.5377479148864746, val loss: 1.9060756227493285\n",
      "\ttrain accuracy 0.9350166666666667, val accuracy: 0.5542\n",
      "Epoch: 38 / 100\n",
      "\ttrain loss: 1.5367716579437256, val loss: 1.9237648754119874\n",
      "\ttrain accuracy 0.9357833333333333, val accuracy: 0.536\n",
      "Epoch: 39 / 100\n",
      "\ttrain loss: 1.5356838219960531, val loss: 1.9054642807006836\n",
      "\ttrain accuracy 0.9364666666666667, val accuracy: 0.5549\n",
      "Epoch: 40 / 100\n",
      "\ttrain loss: 1.5336955379486084, val loss: 1.9613606071472167\n",
      "\ttrain accuracy 0.9376833333333333, val accuracy: 0.4979\n",
      "Epoch: 41 / 100\n",
      "\ttrain loss: 1.5324979342142742, val loss: 1.9204643669128418\n",
      "\ttrain accuracy 0.9386333333333333, val accuracy: 0.5395\n",
      "Epoch: 42 / 100\n",
      "\ttrain loss: 1.5320097039540608, val loss: 1.943842272567749\n",
      "\ttrain accuracy 0.9384, val accuracy: 0.5159\n",
      "Epoch: 43 / 100\n",
      "\ttrain loss: 1.5306367434183756, val loss: 1.913245782852173\n",
      "\ttrain accuracy 0.9397833333333333, val accuracy: 0.5469\n",
      "Epoch: 44 / 100\n",
      "\ttrain loss: 1.5295572987238566, val loss: 1.9146822265625\n",
      "\ttrain accuracy 0.9407166666666666, val accuracy: 0.5452\n",
      "Epoch: 45 / 100\n",
      "\ttrain loss: 1.5279423629760742, val loss: 1.89633736743927\n",
      "\ttrain accuracy 0.9424833333333333, val accuracy: 0.5632\n",
      "Epoch: 46 / 100\n",
      "\ttrain loss: 1.528010109647115, val loss: 1.9165483730316162\n",
      "\ttrain accuracy 0.9419833333333333, val accuracy: 0.5435\n",
      "Epoch: 47 / 100\n",
      "\ttrain loss: 1.5271465110778808, val loss: 1.898360564804077\n",
      "\ttrain accuracy 0.9424166666666667, val accuracy: 0.5619\n",
      "Epoch: 48 / 100\n",
      "\ttrain loss: 1.526060820643107, val loss: 1.9365028827667237\n",
      "\ttrain accuracy 0.9429833333333333, val accuracy: 0.5226\n",
      "Epoch: 49 / 100\n",
      "\ttrain loss: 1.5251827955881754, val loss: 1.937373850631714\n",
      "\ttrain accuracy 0.9443333333333334, val accuracy: 0.5227\n",
      "Epoch: 50 / 100\n",
      "\ttrain loss: 1.5235976107279459, val loss: 1.9238818244934082\n",
      "\ttrain accuracy 0.9458666666666666, val accuracy: 0.5356\n",
      "Epoch: 51 / 100\n",
      "\ttrain loss: 1.5234323808670045, val loss: 1.9457966821670531\n",
      "\ttrain accuracy 0.94515, val accuracy: 0.5142\n",
      "saving model checkpoint...\n",
      "Epoch: 52 / 100\n",
      "\ttrain loss: 1.5226464399973552, val loss: 1.9130336992263794\n",
      "\ttrain accuracy 0.94555, val accuracy: 0.5467\n",
      "Epoch: 53 / 100\n",
      "\ttrain loss: 1.520750391260783, val loss: 1.9197818246841432\n",
      "\ttrain accuracy 0.9479833333333333, val accuracy: 0.5401\n",
      "Epoch: 54 / 100\n",
      "\ttrain loss: 1.5201326366424561, val loss: 1.9229083534240723\n",
      "\ttrain accuracy 0.9481166666666667, val accuracy: 0.5362\n",
      "Epoch: 55 / 100\n",
      "\ttrain loss: 1.519596045811971, val loss: 1.936063650894165\n",
      "\ttrain accuracy 0.9487333333333333, val accuracy: 0.5242\n",
      "Epoch: 56 / 100\n",
      "\ttrain loss: 1.5192591123580932, val loss: 1.9360826972961427\n",
      "\ttrain accuracy 0.9485833333333333, val accuracy: 0.523\n",
      "Epoch: 57 / 100\n",
      "\ttrain loss: 1.5180579977671305, val loss: 1.95070909614563\n",
      "\ttrain accuracy 0.9495, val accuracy: 0.5091\n",
      "Epoch: 58 / 100\n",
      "\ttrain loss: 1.5169781536102296, val loss: 1.9172347595214845\n",
      "\ttrain accuracy 0.9507666666666666, val accuracy: 0.5433\n",
      "Epoch: 59 / 100\n",
      "\ttrain loss: 1.5178390420277914, val loss: 1.9478012323379517\n",
      "\ttrain accuracy 0.9499666666666666, val accuracy: 0.5118\n",
      "Epoch: 60 / 100\n",
      "\ttrain loss: 1.5157428738911947, val loss: 1.8877910179138184\n",
      "\ttrain accuracy 0.95195, val accuracy: 0.5725\n",
      "Epoch: 61 / 100\n",
      "\ttrain loss: 1.5158731550852458, val loss: 1.9280171237945556\n",
      "\ttrain accuracy 0.9515166666666667, val accuracy: 0.5318\n",
      "Epoch: 62 / 100\n",
      "\ttrain loss: 1.514525015258789, val loss: 1.938795835494995\n",
      "\ttrain accuracy 0.9526666666666667, val accuracy: 0.521\n",
      "Epoch: 63 / 100\n",
      "\ttrain loss: 1.5152456878662108, val loss: 1.9595194385528565\n",
      "\ttrain accuracy 0.9518166666666666, val accuracy: 0.5002\n",
      "Epoch: 64 / 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain loss: 1.5148572945276897, val loss: 1.9387126625061035\n",
      "\ttrain accuracy 0.9524666666666667, val accuracy: 0.5213\n",
      "Epoch: 65 / 100\n",
      "\ttrain loss: 1.5135841869354247, val loss: 1.9099799997329712\n",
      "\ttrain accuracy 0.9533333333333334, val accuracy: 0.5493\n",
      "Epoch: 66 / 100\n",
      "\ttrain loss: 1.513214180246989, val loss: 1.9173037818908691\n",
      "\ttrain accuracy 0.9538, val accuracy: 0.5428\n",
      "Epoch: 67 / 100\n",
      "\ttrain loss: 1.511957479095459, val loss: 1.8898064102172851\n",
      "\ttrain accuracy 0.9549333333333333, val accuracy: 0.5709\n",
      "Epoch: 68 / 100\n",
      "\ttrain loss: 1.5126059402465821, val loss: 1.89712621383667\n",
      "\ttrain accuracy 0.9539333333333333, val accuracy: 0.5636\n",
      "Epoch: 69 / 100\n",
      "\ttrain loss: 1.5120945596694946, val loss: 1.912681008529663\n",
      "\ttrain accuracy 0.9542, val accuracy: 0.5479\n",
      "Epoch: 70 / 100\n",
      "\ttrain loss: 1.5114804358800251, val loss: 1.923213600921631\n",
      "\ttrain accuracy 0.9548333333333333, val accuracy: 0.537\n",
      "Epoch: 71 / 100\n",
      "\ttrain loss: 1.5101761950174968, val loss: 1.9019255241394042\n",
      "\ttrain accuracy 0.9560333333333333, val accuracy: 0.558\n",
      "Epoch: 72 / 100\n",
      "\ttrain loss: 1.5113207113901774, val loss: 1.9128236549377442\n",
      "\ttrain accuracy 0.9548333333333333, val accuracy: 0.5471\n",
      "Epoch: 73 / 100\n",
      "\ttrain loss: 1.5093612707773845, val loss: 1.9026583850860597\n",
      "\ttrain accuracy 0.9567666666666667, val accuracy: 0.5585\n",
      "Epoch: 74 / 100\n",
      "\ttrain loss: 1.508955992635091, val loss: 1.9282912475585938\n",
      "\ttrain accuracy 0.9571166666666666, val accuracy: 0.5316\n",
      "Epoch: 75 / 100\n",
      "\ttrain loss: 1.5089839242935181, val loss: 1.9209521108627319\n",
      "\ttrain accuracy 0.9571333333333333, val accuracy: 0.5388\n",
      "Epoch: 76 / 100\n",
      "\ttrain loss: 1.5087346411387126, val loss: 1.9225357557296754\n",
      "\ttrain accuracy 0.9572, val accuracy: 0.5372\n",
      "saving model checkpoint...\n",
      "Epoch: 77 / 100\n",
      "\ttrain loss: 1.5087226790746053, val loss: 1.947360577774048\n",
      "\ttrain accuracy 0.957, val accuracy: 0.5129\n",
      "Epoch: 78 / 100\n",
      "\ttrain loss: 1.508443105061849, val loss: 1.9264205781936645\n",
      "\ttrain accuracy 0.9574833333333334, val accuracy: 0.5336\n",
      "Epoch: 79 / 100\n",
      "\ttrain loss: 1.5069213242848714, val loss: 1.923659128189087\n",
      "\ttrain accuracy 0.9588666666666666, val accuracy: 0.5363\n",
      "Epoch: 80 / 100\n",
      "\ttrain loss: 1.5065086259206135, val loss: 1.9132030548095702\n",
      "\ttrain accuracy 0.9594666666666667, val accuracy: 0.5468\n",
      "Epoch: 81 / 100\n",
      "\ttrain loss: 1.5065874453226726, val loss: 1.9067192306518554\n",
      "\ttrain accuracy 0.95925, val accuracy: 0.554\n",
      "Epoch: 82 / 100\n",
      "\ttrain loss: 1.5067463189442953, val loss: 1.9384788051605224\n",
      "\ttrain accuracy 0.9587833333333333, val accuracy: 0.5218\n",
      "Epoch: 83 / 100\n",
      "\ttrain loss: 1.5062778764724731, val loss: 1.913288716506958\n",
      "\ttrain accuracy 0.9594166666666667, val accuracy: 0.5469\n",
      "Epoch: 84 / 100\n",
      "\ttrain loss: 1.5058240944544474, val loss: 1.9096806266784667\n",
      "\ttrain accuracy 0.9594, val accuracy: 0.5506\n",
      "Epoch: 85 / 100\n",
      "\ttrain loss: 1.5039511800765992, val loss: 1.901595167350769\n",
      "\ttrain accuracy 0.9614333333333334, val accuracy: 0.5586\n",
      "Epoch: 86 / 100\n",
      "\ttrain loss: 1.505460669072469, val loss: 1.9143470386505126\n",
      "\ttrain accuracy 0.95995, val accuracy: 0.5462\n",
      "Epoch: 87 / 100\n",
      "\ttrain loss: 1.5041241181055705, val loss: 1.900365094947815\n",
      "\ttrain accuracy 0.96125, val accuracy: 0.5593\n",
      "Epoch: 88 / 100\n",
      "\ttrain loss: 1.5037352385203044, val loss: 1.925477430343628\n",
      "\ttrain accuracy 0.9614166666666667, val accuracy: 0.535\n",
      "Epoch: 89 / 100\n",
      "\ttrain loss: 1.5038009079615275, val loss: 1.9100237957000732\n",
      "\ttrain accuracy 0.9612333333333334, val accuracy: 0.5502\n",
      "Epoch: 90 / 100\n",
      "\ttrain loss: 1.5027864095052084, val loss: 1.9416403591156006\n",
      "\ttrain accuracy 0.9623333333333334, val accuracy: 0.5182\n",
      "Epoch: 91 / 100\n",
      "\ttrain loss: 1.502827311706543, val loss: 1.9277155799865722\n",
      "\ttrain accuracy 0.9622, val accuracy: 0.5326\n",
      "Epoch: 92 / 100\n",
      "\ttrain loss: 1.5030115412394205, val loss: 1.9237722282409668\n",
      "\ttrain accuracy 0.9618333333333333, val accuracy: 0.5369\n",
      "Epoch: 93 / 100\n",
      "\ttrain loss: 1.503392314783732, val loss: 1.942492680168152\n",
      "\ttrain accuracy 0.96175, val accuracy: 0.5173\n",
      "Epoch: 94 / 100\n",
      "\ttrain loss: 1.5020443415323894, val loss: 1.9622599130630494\n",
      "\ttrain accuracy 0.9626666666666667, val accuracy: 0.4969\n",
      "Epoch: 95 / 100\n",
      "\ttrain loss: 1.5023588334401448, val loss: 1.9011173620224\n",
      "\ttrain accuracy 0.9625166666666667, val accuracy: 0.5592\n",
      "Epoch: 96 / 100\n",
      "\ttrain loss: 1.5020051928202311, val loss: 1.911697956085205\n",
      "\ttrain accuracy 0.9629, val accuracy: 0.5488\n",
      "Epoch: 97 / 100\n",
      "\ttrain loss: 1.5019899300893147, val loss: 1.9005494689941407\n",
      "\ttrain accuracy 0.9626666666666667, val accuracy: 0.5596\n",
      "Epoch: 98 / 100\n",
      "\ttrain loss: 1.5022115889231364, val loss: 1.899099538230896\n",
      "\ttrain accuracy 0.9624333333333334, val accuracy: 0.5596\n",
      "Epoch: 99 / 100\n",
      "\ttrain loss: 1.500973887125651, val loss: 1.8873989459991456\n",
      "\ttrain accuracy 0.9638833333333333, val accuracy: 0.5726\n",
      "Epoch: 100 / 100\n",
      "\ttrain loss: 1.501760246404012, val loss: 1.923059828567505\n",
      "\ttrain accuracy 0.9633833333333334, val accuracy: 0.5369\n",
      "\n",
      "saving history...\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "for epoch in range(100):\n",
    "    print(f'Epoch: {epoch + 1} / {100}')\n",
    "    train_obj = 0\n",
    "    train_acc = 0\n",
    "    n_data = 0\n",
    "\n",
    "    net.train()\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data = atk(data, target).to(dev)\n",
    "        target = target.to(dev)\n",
    "        y = softmax(net.forward(data))\n",
    "        l = loss(y, target)\n",
    "        train_obj += l.sum().item()\n",
    "\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        train_acc += torch.sum(target == pred)\n",
    "        n_data += data.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        l.mean().backward()\n",
    "        optimizer.step()\n",
    "    train_obj /= n_data\n",
    "    train_acc = float(train_acc) / n_data\n",
    "\n",
    "    if val_loader is not None:\n",
    "        val_obj = 0\n",
    "        val_acc = 0\n",
    "        n_data = 0\n",
    "        net.eval()\n",
    "        for i, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(dev)\n",
    "            target = target.to(dev)\n",
    "            y = softmax(net.forward(data))\n",
    "            l = loss(y, target)\n",
    "            val_obj += l.sum().item()\n",
    "            pred = torch.argmax(y, dim=1)\n",
    "            val_acc += torch.sum(target == pred)\n",
    "\n",
    "            n_data += data.size(0)\n",
    "        val_obj /= n_data\n",
    "        val_acc = float(val_acc) / n_data\n",
    "\n",
    "    print(f\"\\ttrain loss: {train_obj}, val loss: {val_obj}\")\n",
    "    print(f\"\\ttrain accuracy {train_acc}, val accuracy: {val_acc}\")\n",
    "    history[\"train_obj\"].append(train_obj)\n",
    "    history[\"val_obj\"].append(val_obj)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    if epoch % 25 == 0 and epoch > 0:\n",
    "        print(\"saving model checkpoint...\")\n",
    "        j = epoch // 25\n",
    "        torch.save(net.state_dict(),\n",
    "                   os.path.join(\"/home/solia/Documents/stochastic_predictors/experiments/exp-b06\",\n",
    "                   \"baseline-adversarial\" + \"-checkpoint\" + str(j) + \".pt\"))\n",
    "        atk = FGSM(net, eps=0.005)\n",
    "\n",
    "print(\"\\nsaving history...\")\n",
    "history_file_p = os.path.join(\"/home/solia/Documents/stochastic_predictors/experiments/exp-b06\",\n",
    "                \"baseline-adversarial\" + \"06\" + \"-history.pickle\")\n",
    "with open(history_file_p, 'wb') as history_file:\n",
    "    pickle.dump(history, history_file, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StochasticCNN(\n",
       "  (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (4): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): Conv2d(12, 12, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (7): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (9): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): ReLU()\n",
       "  (14): Conv2d(48, 48, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (15): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (17): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Conv2d(96, 96, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (20): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (21): Conv2d(96, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (22): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (23): ReLU()\n",
       "  (24): Conv2d(50, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (25): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU()\n",
       "  (27): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(val_dataset, batch_size=5000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 tensor(0.5394)\n",
      "0.005 tensor(0.5290)\n",
      "0.01 tensor(0.5268)\n",
      "0.02 tensor(0.5280)\n",
      "0.05 tensor(0.5160)\n",
      "0.1 tensor(0.4820)\n",
      "0.2 tensor(0.4086)\n",
      "0.5 tensor(0.2074)\n"
     ]
    }
   ],
   "source": [
    "for p in [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5]:\n",
    "    d = nn.Dropout(p=p)\n",
    "    for data, target in test_loader:\n",
    "        y = softmax(net.forward(d(data)))\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        acc = (pred == target).sum() / target.size(0)\n",
    "    print(p, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 tensor(0.8612)\n",
      "0.5 tensor(0.8626)\n",
      "0.5 tensor(0.8600)\n",
      "0.5 tensor(0.8606)\n",
      "0.5 tensor(0.8580)\n",
      "0.5 tensor(0.8702)\n",
      "0.5 tensor(0.8554)\n",
      "0.5 tensor(0.8196)\n",
      "0.5 tensor(0.7828)\n"
     ]
    }
   ],
   "source": [
    "for e in [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "    atk = FGSM(net, eps=e)\n",
    "    for data, target in test_loader:\n",
    "        y = softmax(net.forward(atk(data, target)))\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        acc = (pred == target).sum() / target.size(0)\n",
    "    print(e, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchattacks import BIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05 tensor(0.5426)\n",
      "5e-05 tensor(0.5464)\n",
      "0.0001 tensor(0.5356)\n",
      "0.0005 tensor(0.5378)\n",
      "0.001 tensor(0.5426)\n",
      "0.005 tensor(0.5220)\n",
      "0.01 tensor(0.5140)\n",
      "0.05 tensor(0.4340)\n",
      "0.1 tensor(0.3550)\n"
     ]
    }
   ],
   "source": [
    "for e in [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "    atk = BIM(net, eps=e)\n",
    "    for data, target in test_loader:\n",
    "        y = softmax(net.forward(atk(data, target)))\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        acc = (pred == target).sum() / target.size(0)\n",
    "    print(e, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in test_loader:\n",
    "    y = softmax(net.forward(data))\n",
    "    pred = torch.argmax(y, dim=1)\n",
    "    y_pred, _ = torch.max(y, dim=1)\n",
    "    y_corr, _ = torch.max(y[target == pred], dim=1)\n",
    "    y_wrong, _ = torch.max(y[target != pred][:, pred], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_pred.detach().cpu()\n",
    "y_corr = y_corr.detach().cpu()\n",
    "y_wrong = y_wrong.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_corr = torch.round(y_corr * 10).numpy()\n",
    "y_wrong = torch.round(y_wrong * 10).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([y_corr, y_wrong], bins=11, range=(0, 10), density=True, color=[\"green\", \"red\"])\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "           labels=['0', '.1', '.2', '.3', '.4', '.5', '.6', '.7', '.8', '.9', '1'])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
